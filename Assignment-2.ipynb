{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Web Scraping Using Selenium "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstly we'll install selenium library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\pooja.mishra\\anaconda3\\lib\\site-packages (21.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip --trusted-host pypi.org --trusted-host files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\pooja.mishra\\anaconda3\\lib\\site-packages (21.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pooja.mishra\\anaconda3\\lib\\site-packages (50.3.1.post20201107)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org pip setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries to work on selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are connecting to web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Pooja.Mishra\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. first get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are getting the job search bar by id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"ce524196-aa18-46ec-907e-3c488113ec1b\")>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are automating the search click 'Data Analyst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are finding element for job location bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"049915c3-c6f6-4ab4-8507-f5af34f4f77f\")>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are getting the location 'Bangalore' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Then click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are applying xpath to get the job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_btn = driver.find_element_by_class_name('btn')\n",
    "#search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"85690215-9d70-4b0f-9108-7ba25721d367\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"1bd314c7-aada-489d-b205-4be5f4590fa7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"ac057edf-f8ec-44ba-bbc3-822703f4af79\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"9c58a6b4-32f9-4cc2-8b4c-5657a17aad16\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"9148f78f-3a0d-4549-9edb-0c7c7b00bcbe\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"2163d796-519a-4206-acb4-a7d1d2f3115a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"5821acb2-b7a1-44af-b05e-226513794ab5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"96896d28-05b1-44a5-8d34-1feb8ea850bf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"b55eb19b-a29b-413d-b4a8-4e68b8607457\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"0d29b507-feac-4226-9047-0f5d559c463d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"5faac423-789d-46c9-8dc3-809edd741c15\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"7d56e4fc-7198-48bc-9c57-7d965046a14a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"0ba65b1f-4547-49aa-a646-c41e06c1144f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"ffdfd90e-9d4e-49c0-a786-69d5fb28d560\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"b643b48f-6784-468f-9304-b8fc30d11eaf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"32658493-0ba4-419b-ab99-b5384bcbc457\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"03f4e2fb-1c2d-4f9e-b9f3-201d04a04bab\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"1ff1bc72-c8bd-4a8b-bf3e-66c71f683212\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"e0cc489b-de4f-435a-84f8-ba6b7fe88988\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"e5ece26b-3bb9-4b44-8822-4dded140adf8\")>]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have used for loop to get simplified data for job titles."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Then scrape the data for the first 10 jobs results you get.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Data Analyst - Informatica MDM',\n",
       " 'Assistant Vice President - MIS & Reporting ( Business Data Analyst)',\n",
       " 'Data Analyst',\n",
       " 'Hiring For Data Analyst/ MIS Reporting Analyst - Bangalore',\n",
       " 'Consultant-Data Analyst -Bangalore',\n",
       " 'Data analyst - Google Analytics',\n",
       " 'SW Technologist I- Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Hiring For Data Analyst @ Flipkart on Contract',\n",
       " 'Data Analyst - Informatica MDM',\n",
       " 'Senior Data Analyst',\n",
       " 'Cybersecurity Data Analyst',\n",
       " 'Data Analyst / Business Analyst -',\n",
       " 'Business Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles=[]\n",
    "for i in title_tags:\n",
    "    job_titles.append(i.text)\n",
    "job_titles    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"7d8f41e8-3efc-4489-919d-89b34fa3766d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"e4dfe4f5-60db-4e43-8563-32b9053d511b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"69d2955d-0767-4437-a6de-1f4c6c8e1ed9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"4bfa0b48-9166-45f3-a4ee-26f246747008\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"3b7c3182-d3e5-420c-a74d-ebb7512c1d1d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"7e7825d9-abdd-4d1a-8d5f-e7ede8d5f37a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"c48dae2d-8c5c-4862-93be-7bd1325d5c8e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"adf462ef-df77-4321-9bb1-e7d2e7f88d5b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"77f4a38c-e147-4839-b2c3-18ce83049ac5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"6f3e7dab-4e3d-4823-b393-928fd033ce85\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"6ca1e1e9-7dd6-440e-a370-dc1ff8d992c2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"ef33a180-0efe-44fa-b680-91f30c09d4ff\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"ab1a1d0a-4e9d-4b37-bb39-9fac465e0885\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"90602eee-fd7f-4f74-a395-44d2a32e5360\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"c6147c4a-3118-400a-8930-1a9d366aabca\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"a501d002-6796-483e-9073-eccdfde3d5a9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"97fbb9fe-bf2d-46e3-81e9-e5d975edd137\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"c7e29dd7-da72-40e7-8cee-7546761987d9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"a545c825-b288-4414-a43a-31d230a3e6d0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"9f56897b-1bbd-4a18-8189-dd7537a1c26b\")>]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_location = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mumbai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_locations=[]\n",
    "for i in job_location:\n",
    "    job_locations.append(i.text)\n",
    "job_locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarly we have extracted the company,location, experience, by finding right xpath to get all required elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"48923914-c4c2-4a05-bc8c-fd515205e8a2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"8726af69-06c8-4f23-a786-5de23e3ee440\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"620e7822-05f3-4f8c-861f-d28f7c6d962f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"c2d49863-0e82-401c-a738-a0383831fd1c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"6027662c-4216-46ab-8cbd-9cc4391cd329\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"4339c906-5d56-43de-8b77-a17bd7a74ed1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"bb59fa50-b2f4-4e5b-b804-5605a738d54c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"b24d1240-2ea6-4227-a4cb-0c39a3b8cb60\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"729e47bc-5e12-4650-81f5-1106d01bacf0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"13994dfb-4d9e-4a7a-a06e-af06a4c8ea85\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"98db78fb-4c64-430c-930e-0a657cf0a81c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"4a604599-3786-475f-a388-58dd40199368\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"2c15d2db-b0db-4eb8-a9d3-0765c430159f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"37f7c8d6-f2e3-4f0a-b71a-7636e1fff3b2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"77dbc723-f3dd-480d-a8d8-d47d4b544bdf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"5c4a7af1-b1ce-4aad-8dd0-68ce62e6b413\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"ef6a8550-b244-4083-97b6-1144b7a96f80\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"18a2f943-9b65-446d-8c51-979bba6bbae4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"efdd90c9-073e-4aee-b9f9-4bd4b2261fb9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"698de57a-aaea-4bfc-a0bb-e19d84ba4ef2\")>]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_experience = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "job_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '6-9 Yrs',\n",
       " '12-18 Yrs',\n",
       " '1-3 Yrs',\n",
       " '2-4 Yrs',\n",
       " '2-7 Yrs',\n",
       " '4-7 Yrs',\n",
       " '5-10 Yrs',\n",
       " '1-3 Yrs',\n",
       " '2-6 Yrs',\n",
       " '6-9 Yrs',\n",
       " '2-5 Yrs',\n",
       " '5-8 Yrs',\n",
       " '1-5 Yrs',\n",
       " '5-10 Yrs',\n",
       " '1-6 Yrs',\n",
       " '2-6 Yrs',\n",
       " '2-6 Yrs',\n",
       " '0-3 Yrs',\n",
       " '3-4 Yrs']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_experiences=[]\n",
    "for i in job_experience:\n",
    "    job_experiences.append(i.text)\n",
    "job_experiences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"93a1f3df-c3cd-4f2f-9721-3d51cf04c012\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"53e26502-bfc9-4d88-ae4a-6ab16b1ed387\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"938dfc0e-16b6-4634-bc38-3d78f7d9c93d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"934e713c-3000-46db-8860-b93d726350a0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"1b0c5fa8-0f18-4103-a6a0-e3983765fcd4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"9fcc9041-7a7d-487f-b2fe-2ea37d706547\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"a2b444c8-48a5-4993-b293-b0681b65c847\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"b66e6148-7b97-4fbb-86ad-7570dbed1907\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"aa32d0eb-6005-42e3-a72c-936f973e3a7e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"0259e4ca-7da0-407e-840c-e6388365eef3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"101b48aa-e511-43ed-a751-825812e2c3b9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"c5456d09-04c3-49c7-b12f-b88fcca38f6c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"58c4ab7c-875a-41e5-883b-300d14b304a9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"8f610863-b318-4edf-b23c-6f820cfce99c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"24b56519-ae8f-4cc3-bcc1-2e9c360fd693\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"e55b86cc-b649-4c8d-a812-35375359be7e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"73ee9313-e0cb-4cf5-a939-f8723152411b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"1319d6a7-0745-4367-97ea-460a86a740b3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"7d53db1d-f21b-4b2c-a537-ed8b90c741de\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d468c01b5e434a9fc235ff4da1e25796\", element=\"4949e2a8-7d1a-4887-abb3-d457f5819762\")>]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_company= driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "job_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Shell India Markets Private Limited',\n",
       " 'INTERTRUSTVITEOS CORPORATE AND FUND SERVICES PVT. LTD.',\n",
       " 'SA Tech Software (I) Pvt. Ltd.',\n",
       " 'PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd',\n",
       " 'Innovsource Services Private Limited',\n",
       " 'H and M Hennes and Mauritz (P) Ltd.',\n",
       " 'Philips India Limited',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Shell India Markets Private Limited',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Huawei Technologies India Pvt Ltd',\n",
       " 'LatentView Analytics Private Limited',\n",
       " 'ALSTOM India Limited',\n",
       " 'Udaan',\n",
       " 'Luxoft',\n",
       " 'Yodlee Infotech Private Limited',\n",
       " 'Novel Office',\n",
       " 'Bytech India Private Limited']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_companies=[]\n",
    "for i in job_company:\n",
    "    job_companies.append(i.text)\n",
    "job_companies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we got all required data now we'll frame the dataframe to display top 10 job details including experience, company, job titles."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Finally create a dataframe of the scraped data by performing manual task with help of selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>experience</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Informatica MDM</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Kolkata, Pune, Chennai, Bangalore/Bengaluru, D...</td>\n",
       "      <td>SA Tech Software (I) Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For Data Analyst/ MIS Reporting Analyst...</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consultant-Data Analyst -Bangalore</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Innovsource Services Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data analyst - Google Analytics</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>H and M Hennes and Mauritz (P) Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SW Technologist I- Data Analyst</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst @ Flipkart on Contract</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title experience  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst    0-3 Yrs   \n",
       "1                     Data Analyst - Informatica MDM    6-9 Yrs   \n",
       "2  Assistant Vice President - MIS & Reporting ( B...  12-18 Yrs   \n",
       "3                                       Data Analyst    1-3 Yrs   \n",
       "4  Hiring For Data Analyst/ MIS Reporting Analyst...    2-4 Yrs   \n",
       "5                 Consultant-Data Analyst -Bangalore    2-7 Yrs   \n",
       "6                    Data analyst - Google Analytics    4-7 Yrs   \n",
       "7                    SW Technologist I- Data Analyst   5-10 Yrs   \n",
       "8                                       Data Analyst    1-3 Yrs   \n",
       "9     Hiring For Data Analyst @ Flipkart on Contract    2-6 Yrs   \n",
       "\n",
       "                                            location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                        Mumbai, Bangalore/Bengaluru   \n",
       "3  Kolkata, Pune, Chennai, Bangalore/Bengaluru, D...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                             company  \n",
       "0                 Inflexion Analytix Private Limited  \n",
       "1                Shell India Markets Private Limited  \n",
       "2  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...  \n",
       "3                     SA Tech Software (I) Pvt. Ltd.  \n",
       "4   PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd  \n",
       "5               Innovsource Services Private Limited  \n",
       "6                H and M Hennes and Mauritz (P) Ltd.  \n",
       "7                              Philips India Limited  \n",
       "8                  Flipkart Internet Private Limited  \n",
       "9                  Flipkart Internet Private Limited  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we got complete solution of ques.1\n",
    "\n",
    "jobs = pd.DataFrame({})\n",
    "jobs[\"title\"] = job_titles\n",
    "jobs[\"experience\"] = job_experiences\n",
    "jobs[\"location\"] = job_locations\n",
    "jobs[\"company\"] = job_companies\n",
    "jobs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location,company_name, full job-description. You have to scrape first 10 jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstly we are connecting to web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Pooja.Mishra\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. first get the webpage https://www.naukri.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the url 'naukri.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "naukri_url='https://www.naukri.com/'\n",
    "driver.get(naukri_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter \n",
    "“Bangalore” in “enter the location” field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now finding the element for search bar to fetch required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findling search element by id\n",
    "search_bar=driver.find_element_by_id(\"qsb-keyword-sugg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write 'Data Scientist' in search bar\n",
    "search_bar.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findling search element by id for location\n",
    "search_location=driver.find_element_by_id(\"qsb-location-sugg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing 'Bangalore in location bar' by sending keys\n",
    "search_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now click using the xpath function\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By above coding we got the page opened with jobs listing with title 'Data Scientist' for location 'Bangalore'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we'll extract the job titles tags where we have job titles by xpath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the tags for job titkes; so we will run a loop to extract all the job titkes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Senior Data Scientist, Modeling',\n",
       " 'Data Scientist - IBM Garage',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist - Credit risk',\n",
       " 'Big Data - Data Scientist',\n",
       " 'SDE Lead Data Scientist-L3',\n",
       " 'Computational Design Lead Data Scientist-L3',\n",
       " 'Data Scientist',\n",
       " 'Lead Data Scientist',\n",
       " 'Senior Data Scientist - Chatbot & NLP',\n",
       " 'Senior Data Scientist - Chatbot & NLP',\n",
       " 'Hiring For Lead data Scientist For Bangalore location',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist - Kinara Capital',\n",
       " 'Senior Data Scientist, Marketing Analytics',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist/ Senior Data Scientist',\n",
       " 'Principal Data Scientist',\n",
       " 'Lead Data Scientist /Sr. Data Scientist']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#by this we'll get the list of all top listed job titles\n",
    "jobs=[]\n",
    "for i in job_titles:\n",
    "    jobs.append(i.text)\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll extract the tags for company names by xpath\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Nielsen',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Scienaptic Systems',\n",
       " 'Xoriant Solutions Pvt Ltd',\n",
       " 'Huawei Technologies India Pvt Ltd',\n",
       " 'Huawei Technologies India Pvt Ltd',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Intel Technology India Pvt Ltd',\n",
       " 'Gojek Tech',\n",
       " 'GO-JEK India',\n",
       " 'Societe Generale',\n",
       " 'Kinara Financial Private Limited',\n",
       " 'Kinara Financial Private Limited',\n",
       " 'Hudsons Bay Company',\n",
       " 'Applied Materials',\n",
       " 'o9 Solutions Management India Private Limited',\n",
       " 'NetApp',\n",
       " 'BDITDOMAIN']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we'll extract the text from the tags one by one by using for loop\n",
    "companies=[]\n",
    "for i in company_tags:\n",
    "    companies.append(i.text)\n",
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Getting the tags for location by xpath\n",
    "loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru, Vadodara, Mumbai (All Areas)',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kochi/Cochin, Indore, Hyderabad/Secunderabad, Pune, Ahmedabad, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all locations from above tags\n",
    "locations=[]\n",
    "for i in loc_tags:\n",
    "    locations.append(i.text)\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we got all required data now we'll frame the dataframe to display top 10 job details including company, job titles.\n",
    "#So, Now we'll work on extracting the job description by Exception Hnadling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Exception Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"ab1033d5-1514-443f-bf7a-5693997505e8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"8c57ef5e-e5d3-4983-9417-0ff3c48186e6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"37d738ed-22ee-420e-baa5-69c3cd165282\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"7e86cbc5-0eed-4e47-bb22-38212c346816\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"c9399578-48b9-40ad-83d2-82935421cd84\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"d4366712-3b0f-4db2-bce2-da1a7d4e67b3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"e7f2306d-9785-4457-9973-8536d9e9d9c2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"5c1c0641-b69a-494e-8f6f-5ca4ea7c7c30\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"aea8ed8f-2efe-4082-9b58-7fb6bc014403\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"38a2a708-bd23-4b6a-bcbc-4c89c5e39d25\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"0e766799-6662-4c90-ac91-9327002b074b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"3569c2b7-efc4-4cc1-836a-1a826526eb91\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"143d4f77-5ddf-4904-8ed0-0634061c9cb4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"81413955-b8bd-4886-90df-e4c858b7e127\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"fadd1e3a-68fb-41c6-801c-98a417a7eb2c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"aa0b7d43-a428-420f-88d7-de040a9b34a4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"b376f6ed-4ca1-4417-b99c-67a06105907b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"0412b12c-9e65-4ab0-915f-6deb6ff6154b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"abe2c302-55a9-4fde-979e-5d18593370a2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"128ae1c28459457e4045299a93e8a4ff\", element=\"e9012d20-98e5-49bf-be60-611c3da908ca\")>]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_desc_elements=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_desc_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Pooja.Mishra\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Job description Job Role : Data Scientist/Data Analyst /Business Analyst  Location : Chennai/Bangalore/Hyderabad/Pune/Mumbai/Delhi  Greetings from CAIA - Center for Artificial Intelligence & Advanced Analytics 43% of companies experienced a high deficit of skilled resources with Advanced Analytical skills and AI implementing capabilities in year 2020. CAIA gives you a great opportunity to enter the world of future technologies and Innovations- Data Science, Analytics, AI, Data Visualization and Cloud Computing.  While 2020 was a year like no other, we are living in an interesting times where data is reshaping the world, and businesses are rapidly adopting technology to gain an edge over others. Hence, there's a substantial increase in demand for technology professionals who can implement systems in data science, machine learning and AI in Tier 1 and Tier 2 organization's working closely with us.  To help you build a sustainable career we would like you to utilize data, software and Analytical approaches in Data Science and AI to up skill and get recruited into an organization appreciating your skilling journey. Applications invited from all Freshers and experienced candidates (0-3 yrs) aspiring to make a career in Artificial Intelligence and Advanced Analytics and Data Science. If you wish to make a shift in your career or undergo a career transition, upskilling is essential since it allows you to learn more about the domain and acquire the required skills.  Call to schedule interview Monday -Saturday from 10:00 am to 7Pm  Manigandan -+91 7299917200  Email : manigandan@centerforaia.com  What is needed from you?  Freshers who wish to start their career in Analytics and AI and professionals who wish to upskill or change their domain to analytics and emerging technologies are free to apply. An Educational background in any one of the following- BE/B.Tech, ME/M Tech, MSc, BSc/MSc Maths and Statistics, B Com, BCA, BSc CS, BSC IT, MSC IT, MCA Skills relating to Mathematics/Statistics. Natural passion towards numbers, business, coding, Analytics and Artificial Intelligence, Machine Learning, visualization Good verbal and written communication skills Ability to understand domains in businesses across various sectors   Selection procedure includes  Aptitude Test & Communication Exam - Online / Offline SQL/Python test - Online / Offline  Candidates who clears the above will have one-one discussion with our Career Guidance Manager for further evaluation and processing of your Resume.   All the Shortlisted candidates will be eligible to continue the corporate training with CAIA What you can expect from us?  You will get trained on the following modules for a period of 12-14 weeks:  SQL & PLSQL Data Wrangling using Python Data Visualization Using Power-BI Statistics for Machine Learning Artificial Intelligence, Data Interpretation Supervised & Unsupervised Learning, NLP & Deep Learning Cloud Data Lake Business intelligence & Data Visualization Simulation Projects Expected Outcome?  At the end of the Training you are expected to be well versed with the following:  Analysis of large and complex data sets from multiple sources Development and evaluation of data analytics models, algorithms and solutions Understanding/implementation of ML algorithms, performance tuning and reporting Implementation of algorithms to mine targeted data and the ability to convert data in to a business story Translation of business requirements into technical requirements; Data extraction, preparation and transformation Identification, development and implementation of statistical techniques and algorithms that address business challenges and adds value to the organization Requirement Analysis and communication of findings in the form of a meaningful story with the stakeholders Finding analytical solutions to abstract business issues. Apply objective analysis of facts before coming to a conclusion  About CAIA - Inflexion Analytix Private Limited  Center for Artificial Intelligence and Advanced Analytics (Center for AIA) is the brainchild of experienced and visionary alumni of IIT Madras and Bombay. Digital leaders - 5F World and Systech Solutions have joined hands to create a venture for architecting the future of society, workforce, governments and businesses. 5F World specializes in designing solutions around digital platforms and Systech Solutions has an expertise in architecting Artificial Intelligence and Advance Analytics solutions for Fortune 500 companies. Our Website : http://www.centerforaia.com/  https://inflexion-analytix-private-limited.business.site/?m=true  Center for Artificial Intelligence & Advanced Analytics (CAIA) focuses on the following:  1. Global Research on emerging trends, technologies and applications in AI and Advanced Analytics 2. Advanced Training programs for readying the future ready workforce 3. Solutions to herald the futuristic lifestyle and workspaces in the field of AI and Data Science. RoleData Analyst Industry TypeBPO / Call Centre Functional AreaAnalytics & Business Intelligence Employment TypeFull Time, Permanent Role CategoryAnalytics & BI Education UG :Any Graduate in Any Specialization Key Skills Business IntelligenceArtificial IntelligenceBig DataITMachine LearningStatisticsDeep LearningAnalyticsBusiness AnalysisSQLData ScienceNLPCloud ComputingData VisualizationSoftwareData WarehousingPython\",\n",
       " 'Job description We wont say we can predict the future, but our team of Analysts get pretty close, they turn millions of data points into useful information & insights that help our clients to make better decisions on their marketing mix and achieve superior results. Be part of the future and join in on one of the major transformations in the market research industry with the integration of big data and classic marketing mix analysis.  Responsibilities: Deliver as a part of our consultant team in driving high quality results on custom project work Ensure effective and timely delivery of project work Work towards understanding statistical models and deliver business insights and findings Ensure compliance to Marketing Mix Modeling modeling practices and company quality standards Maximize the efficient and effective use of resources by utilizing appropriate processes and tools To build and maintain effective contacts with other departments to ensure the efficient and effective use of resources Liaise with appropriate Marketing Mix Modeling and Nielsen departments to ensure hardware and software requirements are fulfilled Work with co/ third party modellers to deliver business insights and findings  Qualifications and Skills 2-5 years of relevant experience Masters degree in Economics, Mathematics, Statistics, Engineering In-depth understanding of statistical modeling techniques and applications Good and working knowledge of any statistical languages like SAS, R, Pythons Solid proficiency of decision making and problem resolution skills Passion for results with a challenger mindset  About the Team: Global Product, Technology & Operations supports Nielsen Medias growth strategy by enabling positive client and market solutions. Our Operations Team is in a unique position as the center of data collection, analysis and delivery. We deliver outcomes with the highest quality and integrity standards in an agile and transparent way while standing by our Nielsen values.   RoleBusiness Analyst Industry TypeAnalytics / KPO / Research Functional AreaStrategy, Management Consulting, Corporate Planning Employment TypeFull Time, Permanent Role CategoryCorporate Planning/Consulting/Strategy Education PG :MBA/PGDM in Any Specialization, MS/M.Sc(Science) in Statistics, Maths, M.A in Economics Key Skills Predictive ModelingSASSegmentationK-MeansStatisticsOptimizationRandom ForestRMarketing Mix ModelingLinear RegressionStatistical ModelingBusiness InsightsMarket Research',\n",
       " '-',\n",
       " '-',\n",
       " 'Job description  Responsibilities and duties Focus on developing clear and concise analytical approach for problem solving with client partnership Strong understanding of ML libraries and applications e.g. Neural Net, SVMs, boosting methods and implementation using R/Python. Should have academic paper level understanding of math e.g. linear algebra, calculus etc. Ability to code on SAS/R for data munging, analysis and insights and/or languages like Python for creating efficient production ready code Managing delivery of projects including timely communication, setting milestones and tracking Generating actionable insights for business/KPI improvements Ability to work independently, structure analyses and handle multiple priorities Develop and Maintaining Credit Risk Models Strategies Rich experience in at least one production ready deployment of Machine Learning algorithms is a plus. Experience in working on real life large messy dataset to solve real business problems. Kaggle experience is a plus.   Skills Competencies: Experience in Financial Services/ Fintech/ BFSI along with Credit Risk in Retail Banking and Data Science 5 years of experience in building predictive models (Application Scorecard, Behaviour Scorecard, Collection Score Card, Loan Pricing, Loss Forecasting, Cross Sell Model) Experienced Statistical software skills (e.g. SAS, R, Python Strong understanding of ML libraries and applications. Strong experience in leading credit risk model development, validation, deployment, and documentation Analytically oriented with ability to grasp complex risk management strategies, processes, models and draw insights / identify areas of opportunity Strong track record of delivering on high value / critical projects. Ability to communicate with senior stakeholders crisply and confidently on findings, status, bottlenecks, and escalations Proven track record of delivering in a start-up environment would be a plus Strong written and oral communication skills RoleOutside Technical Consultant Industry TypeIT Services & Consulting Functional AreaIT Software - System Programming Employment TypeFull Time, Permanent Role CategorySystem Design/Implementation/ERP/CRM Education UG :Any Graduate in Any Specialization PG :Post Graduation Not Required Key Skills CVSBfsiAnalyticalMachine learningCredit riskData miningRisk managementForecastingFinancial servicesPython',\n",
       " '-',\n",
       " 'Job description Business & Team overview: Founded in 1987, Huawei is a leading global provider of ICT (information and communications technology) infrastructure and smart devices. We are committed to bringing digital to every person, home and organization for a fully connected, intelligent world. We have nearly 194,000 employees, and we operate in more than 170 countries and regions, serving more than 3 billion people around the world.  Huawei Technologies has three business directions: Carrier Business Group, which provides innovative and secure network equipment to telecom carriers, including the leading 5G mobile network. Enterprise Business Group, which provides facilities and solutions to big and small companies, including IT facilities. Consumer Business Groups, which provides devices to the customer, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and headphones. And also provide solutions on mobile offices, smart homes, sports and health, audio-visual entertainment, and smart travel products.  This opportunity is belong to Huawei Consumer Business Group.  Driven by the coordinated development of \"Chip-Device-Cloud\", consumer products such as smartphones are becoming increasingly intelligent and pervasive. The era of smart services is the future.  Huawei Ads Services is dedicated to provide Huawei end-users with high-quality digital experiences, to build a business closed-loop system for Developers and Improve the ROI for the Advertisers . In 2020 Q1, along with more than 650 million users and 1,400,000 registered developers worldwide, we have the following unique advantages: 1. With All-scenario intelligent solution, the Huawei devices become super entrance of traffic, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and head phones 2. This team will be responsible for building a new Ad Serving Platform and have the opportunity to define the product for our Huawei end-users. 3. AI-Driven is the direction of Ads, Huawei is going to build a strong team in India to Innovate and deliver AI-driven Smart Ad Serving Platforms  Job Title: Lead Data Scientist We are looking for a Lead data scientist who will help us discover the information hidden in vast amounts of Ad Campaign data, and help us to optimize the campaign to improve the advertiser ROI and improve the overall consumer experience. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems using Deep learning algorithms integrated with our products. Some the key area you will be working on spend recommendation, floor price prediction, CTR/CVR prediction, market funnel analysis and perdition of lead to conversion, etc.  Responsibility: Analyze the data, develop insights and identify the opportunity to utilize the data to predict various Advertisement key indicators like CTR, CVR, Inventory and Develop prediction and optimization algorithms for campaign, look alike modeling, etc for Huawei Ads. Takeup key challenges in AI-driven Smart Ad Serving Platform and focus on research and developing leading AI algorithms and productionize for Huawei Ads. Takeup initiative in identifying the SOTA and finding key gaps in AI algorithms and develop a world leading AI algorithms for optimizing real-time Ad Serving engine. Identify and optimize the core modules such as Traffic Prediction, Optimization, Ad Targeting/Re-targeting, Ad Performance Optimization, Audience insights, Attribution, Bidding, re-ranking, and Diagnostics. Support hundreds of billions of ad requests per day, with efficiently cache technology. To build and enhance Ad platform features and Prediction capabilities in Huawei Ads Platform Optimized Cost Per Mille; Optimized Cost Per Action; Optimized Cost Per Click and Cost per Click. OCPM, OCPA, OCPC.  Requirements: - Strong hands-on experience in implementing and validating big data algorithms and models including Deep Learning models like Seq2Seq/ GRU/RNN/LSTM , Knowledge Graph, Massive Graph algorithms, etc. - Programming experience with Python - Able to validate existing models including Deep Learning models with large scale dataset and able to make changes to the models to achieve better performance - AdServing domain Experience is an added advantage RoleAnalytics Manager Industry TypeTelecom / ISP Functional AreaAnalytics & Business Intelligence Employment TypeFull Time, Permanent Role CategoryAnalytics & BI Education UG :Any Graduate in Any Specialization PG :Any Postgraduate in Any Specialization Key Skills RnnAlgorithmsLstmArtificial IntelligenceData ScientistBig DataData MiningStatistical AnalysisDeep LearningPython',\n",
       " 'Job description Business & Team overview: Founded in 1987, Huawei is a leading global provider of ICT (information and communications technology) infrastructure and smart devices. We are committed to bringing digital to every person, home and organization for a fully connected, intelligent world. We have nearly 194,000 employees, and we operate in more than 170 countries and regions, serving more than 3 billion people around the world.  Huawei Technologies has three business directions: Carrier Business Group, which provides innovative and secure network equipment to telecom carriers, including the leading 5G mobile network. Enterprise Business Group, which provides facilities and solutions to big and small companies, including IT facilities. Consumer Business Groups, which provides devices to the customer, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and headphones. And also provide solutions on mobile offices, smart homes, sports and health, audio-visual entertainment, and smart travel products.  This opportunity is belong to Huawei Consumer Business Group.  Driven by the coordinated development of \"Chip-Device-Cloud\", consumer products such as smartphones are becoming increasingly intelligent and pervasive. The era of smart services is the future. Huawei Ads Services is dedicated to provide Huawei end-users with high-quality digital experiences, to build a business closed-loop system for Developers and Improve the ROI for the Advertisers . In 2020 Q1, along with more than 650 million users and 1,400,000 registered developers worldwide, we have the following unique advantages: 1. With All-scenario intelligent solution, the Huawei devices become super entrance of traffic, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and head phones 2. This team will be responsible for building a new Ad Serving Platform and have the opportunity to define the product for our Huawei end-users. 3. AI-Driven is the direction of Ads, Huawei is going to build a strong team in India to Innovate and deliver AI-driven Smart Ad Serving Platforms  1. Job Title: Computational Design Lead Data Scientist  Responsibility: Take-up Key creative tools of the creative platform for Advertisers, research and develop breakthrough CNN based deep learning algorithms to solve the problem unique in the industry and productionize the algorithms, measure the ad creative performance and enhance the algorithm to ease the Ad Designer job. Develop the common AI platforms and frameworks to ease the experimentation of the Algorithms for creative Design. To build ability to understand the advertisers intent and provide creative assistance every step of creating all types of adverts Responsible for intelligent identification of advertising creatives (pictures, videos) and related algorithms of content understanding. Responsible for Image Synthesis, Intelligent Layout, Style Transfer, and other image processing, computing and visual processing, to improve the aesthetic level of advertising creativity. Responsible for designing algorithms for suggesting how to intelligently crop and position an image for maximum effect, identify the optimal placement of text and copywriting. Responsible for the algorithm and model of dynamic matching of advertising program creativity and dynamic creation of advertising content  Requirements: Deep knowledge of Computational Design Experience on Intelligent composition, including image cropping, smart layout, the Gold Ratio composition, visual extension. Experience computer vision models, including image/video recognition and content understanding. Experience in algorithms such as image and video segmentation, separation, synthesis, and intelligent layout with engineering platform implementation capability. Strong Knowledge Algorithms such as Image segmentation, object detection, Image processing (filtering, noise removal, histogram thresholding, etc.), object tracking, image transformation (affine transform, dewarping), keypoint detection/description, etc (and experience in using Computer vision Libraries) Strong Knowledge in CNN, R-CNN, GAN, LSTM, GRU, Multimodal feature Learning, ASR, NLU, NLG, Copywriting and KG will be an added advantage Strong logic/probability thinking ability and be good at analyzing, summarizing, describing, communicating, and solving problems Working experience in related online advertising products/creative platform is preferred Working experience in Computer Vision (CV) to enhance user artistic creativity while creating creatives/adverts is preferred Ability to identify trends of advertising creative platform.   RoleData Analyst Industry TypeTelecom / ISP Functional AreaAnalytics & Business Intelligence Employment TypeFull Time, Permanent Role CategoryAnalytics & BI Education UG :Any Graduate in Any Specialization PG :Any Postgraduate in Any Specialization Key Skills Object DetectionR-CNNCnnAlgorithmsLstmGANArtificial IntelligenceImage ProcessingData ScientistComputer VisionComputational DesignDeep Learning',\n",
       " '-',\n",
       " 'Job description   We are seeking an outstanding Lead Data Scientist in AI/ML who will help our team continue to grow and bring high value to Intel. In this role you should demonstrate excellent problem formulation/definition skills in addition to technical skills. The ideal candidate should be:  A professional role model with deep and wide expertise in state-of-the-art AI/ML techniques, a passion for solving challenging data science problems and extensive hands-on experience. Be detail-oriented and have an aptitude for solving unstructured problems. You should be excellent in coming up with different approaches to solve business problem using AI and evaluate the trade-off between them. Be self-directed, take charge of opportunities with business impact and drive them to completion. Have prior experience in guiding a team of data scientists, coaching and mentoring them. Have deep technical expertise in feature-engineering of massive datasets, effective exploratory data analysis, and model building using AI/ML techniques. Be a role model innovator by adapting new AI/ML modeling techniques and procedures. Have deep expertise in creation and management of datasets. Have excellent business and communication skills to be able to work with stakeholders like the business teams, engineering teams and partner teams and align them with respect to your focus area. Have the ability to manage and execute an entire AI project from start to finish, including problem solving, data gathering and manipulation, predictive modeling, and project management skills. Be a role-model in storytelling with data and articulating the AI problems in an understandable manner to senior leadership of the Business Units.  You will be a part of the large global AI/ML Research Scientist community and will have access to state-of-the-art training, tools, and methods of the domain.   Candidates need to hold at least a masters degree (or higher) in Computer Science/Machine Learning/AI/Data Science 8 years of relevant experience in building AI/ML models and in using Python (Scikit-learn, TensorFlow/Pytorch) and SQL (or equivalent). Experience in using data analysis techniques and ML methods like classification, regression pattern finding, clustering, dimensionality reduction, anomaly detection etc. Experience with Hadoop, Spark is an advantage Deep Knowledge of classical AI algorithms and Deep Learning techniques is a must. Great analytical skills and demonstrated ability of independent and creative thinking. Highly motivated strong team player with the ability to work both independently and collaboratively within a team. Has strong analytical skills, including the abilities to scope out business problems to be solved, start from ambiguous problem statements, identify and access relevant data, make appropriate assumptions, perform insightful analysis and draw conclusions relevant to the business problem. Ability to present information professionally and concisely with supporting data. Previous experience as a data scientist in semi-conductor industry or data intensive organizations is a plus. Experience in creating powerful data driven visualizations to describe ML modeling results to stakeholders. RoleTeam Lead/Technical Lead Industry TypeIT Services & Consulting Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :Any Graduate in Any Specialization PG :Any Postgraduate in Any Specialization Key Skills Computer scienceData analysisFormulationArtificial IntelligenceMachine learningSignal processingPredictive modelingForecastingSQLPython']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "desc_list=[]\n",
    "for i in range(0, len(job_desc_elements)-10):\n",
    "    #Getting urls from elements\n",
    "        url = job_desc_elements[i].get_attribute('href')\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            job_desc=driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "            desc_list.append(job_desc.text.replace('\\n',' '))\n",
    "        except NoSuchElementException:\n",
    "            desc_list.append('-')\n",
    "desc_list           \n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(desc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus we got all top 10 job description list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(jobs),len(locations),len(companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Job description Job Role : Data Scientist/Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>Job description We wont say we can predict the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist - Credit risk</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>Job description  Responsibilities and duties F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Big Data - Data Scientist</td>\n",
       "      <td>Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...</td>\n",
       "      <td>Xoriant Solutions Pvt Ltd</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SDE Lead Data Scientist-L3</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>Job description Business &amp; Team overview: Foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Computational Design Lead Data Scientist-L3</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>Job description Business &amp; Team overview: Foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Intel Technology India Pvt Ltd</td>\n",
       "      <td>Job description   We are seeking an outstandin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title  \\\n",
       "0  Data Scientist / Data Analyst -Business Analyst   \n",
       "1                  Senior Data Scientist, Modeling   \n",
       "2                      Data Scientist - IBM Garage   \n",
       "3                                   Data Scientist   \n",
       "4              Senior Data Scientist - Credit risk   \n",
       "5                        Big Data - Data Scientist   \n",
       "6                       SDE Lead Data Scientist-L3   \n",
       "7      Computational Design Lead Data Scientist-L3   \n",
       "8                                   Data Scientist   \n",
       "9                              Lead Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...   \n",
       "2  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "3  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                              Company  \\\n",
       "0  Inflexion Analytix Private Limited   \n",
       "1                             Nielsen   \n",
       "2              IBM India Pvt. Limited   \n",
       "3              IBM India Pvt. Limited   \n",
       "4                  Scienaptic Systems   \n",
       "5           Xoriant Solutions Pvt Ltd   \n",
       "6   Huawei Technologies India Pvt Ltd   \n",
       "7   Huawei Technologies India Pvt Ltd   \n",
       "8              IBM India Pvt. Limited   \n",
       "9      Intel Technology India Pvt Ltd   \n",
       "\n",
       "                                                Desc  \n",
       "0  Job description Job Role : Data Scientist/Data...  \n",
       "1  Job description We wont say we can predict the...  \n",
       "2                                                  -  \n",
       "3                                                  -  \n",
       "4  Job description  Responsibilities and duties F...  \n",
       "5                                                  -  \n",
       "6  Job description Business & Team overview: Foun...  \n",
       "7  Job description Business & Team overview: Foun...  \n",
       "8                                                  -  \n",
       "9  Job description   We are seeking an outstandin...  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we got complete solution of ques.2 \n",
    "import pandas as pd\n",
    "Data_sci = pd.DataFrame({})\n",
    "Data_sci[\"Title\"] = jobs[:10]\n",
    "Data_sci[\"Location\"] = locations[:10]\n",
    "Data_sci[\"Company\"] = companies[:10]\n",
    "Data_sci[\"Desc\"] = desc_list\n",
    "Data_sci.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:You have to use the location and salary filter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=driver = webdriver.Chrome(r\"C:\\Users\\Pooja.Mishra\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the url\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter \"Data Scientist\" in Search bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the element for job location by id\n",
    "search_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_location.send_keys(\"Delhi/NCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click using xpath function\n",
    "click_search=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "click_search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after click we'll see the window opened with list of jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "try:\n",
    "        \n",
    "        location_filter=driver.find_element_by_xpath(\"//span[text()='Delhi / NCR']\")\n",
    "        location_filter.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        salary_filter=driver.find_element_by_xpath(\"//span[text()='3-6 Lakhs']\")\n",
    "        salary_filter.click()\n",
    "except NoSuchElementException:\n",
    "    print(1)\n",
    "        \n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are the webpage with selected filter of 'location' as 'Delhi / NCR' & 'salary' as '3-6 Lakhs'. In order to extract the job-title, job-location, company_name, experience_required data we'll get its tags first by using xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Business Analyst- Data Scientist',\n",
       " 'Data Scientist - High growth VC backed Influencer Marketplace',\n",
       " 'DATA Scientist – Gurgaon (Exp 3-6 years)',\n",
       " 'DATA Scientist – Gurgaon (Exp 3-6 years)',\n",
       " 'Data Scientist - Noida',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist II 5+ yrs II Gurgaon']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the jobs tags\n",
    "job_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#now we'll extract all the tags having the job titles using for loop\n",
    "jobs_titles=[]\n",
    "for i in job_tags[:10]:\n",
    "    jobs_titles.append(i.text)\n",
    "jobs_titles\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Noida, Gurgaon/Gurugram',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpur, Ghaziabad, Jaunpur, Kanpur, New Delhi, Lucknow, Agra, Gurgaon/Gurugram, Rajkot, Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the jobs tags\n",
    "job_loc=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "\n",
    "#now we'll extract all the tags having the job locations using for loop\n",
    "jobs_location=[]\n",
    "for i in job_loc[:10]:\n",
    "    jobs_location.append(i.text)\n",
    "jobs_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Wipro',\n",
       " 'Ravgins International Pvt. Ltd.',\n",
       " 'CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVATE L IMITED',\n",
       " 'CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVATE L IMITED',\n",
       " 'Optum Global Solutions (India) Private Limited',\n",
       " 'Blitz Jobs',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Country Veggie',\n",
       " 'Zenatix Solutions Private Limited']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the company_names tags\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "#now we'll extract all the tags having the company_names using for loop\n",
    "company_names=[]\n",
    "for i in company_tags[:10]:\n",
    "    company_names.append(i.text)\n",
    "company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-6 Yrs',\n",
       " '3-6 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-5 Yrs',\n",
       " '4-9 Yrs',\n",
       " '1-3 Yrs',\n",
       " '5-10 Yrs']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the experience_required tags\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "\n",
    "#now we'll extract all the tags having the company_names using for loop\n",
    "experience_required=[]\n",
    "for i in experience_tags[:10]:\n",
    "    experience_required.append(i.text)\n",
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we got all required data so we can create its dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Jobs_Location</th>\n",
       "      <th>Company_Names</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst- Data Scientist</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - High growth VC backed Influen...</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Ravgins International Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Blitz Jobs</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist II 5+ yrs II Gurgaon</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Zenatix Solutions Private Limited</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                   Business Analyst- Data Scientist   \n",
       "2  Data Scientist - High growth VC backed Influen...   \n",
       "3           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "4           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "5                             Data Scientist - Noida   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9         Senior Data Scientist II 5+ yrs II Gurgaon   \n",
       "\n",
       "                                       Jobs_Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                            Noida, Gurgaon/Gurugram   \n",
       "2  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "3                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "4                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "5                                              Noida   \n",
       "6                                              Noida   \n",
       "7  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "8  Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...   \n",
       "9                                   Gurgaon/Gurugram   \n",
       "\n",
       "                                       Company_Names Experience_Required  \n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1                                              Wipro             2-5 Yrs  \n",
       "2                    Ravgins International Pvt. Ltd.             3-5 Yrs  \n",
       "3  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...             3-6 Yrs  \n",
       "4  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...             3-6 Yrs  \n",
       "5     Optum Global Solutions (India) Private Limited             3-5 Yrs  \n",
       "6                                         Blitz Jobs             3-5 Yrs  \n",
       "7                             IBM India Pvt. Limited             4-9 Yrs  \n",
       "8                                     Country Veggie             1-3 Yrs  \n",
       "9                  Zenatix Solutions Private Limited            5-10 Yrs  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we got complete solution of ques.3 \n",
    "import pandas as pd\n",
    "Data_filters = pd.DataFrame({})\n",
    "Data_filters[\"Title\"] = jobs_titles\n",
    "Data_filters[\"Jobs_Location\"] = jobs_location\n",
    "Data_filters[\"Company_Names\"] = company_names\n",
    "Data_filters[\"Experience_Required\"] = experience_required\n",
    "Data_filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. \n",
    "You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. first get the webpage https://www.glassdoor.co.in/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling web driver\n",
    "driver=driver = webdriver.Chrome(r\"C:\\Users\\Pooja.Mishra\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the url\n",
    "url=\"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida”\n",
    "in “location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter \"Data Scientist\" in Search bar by using id.\n",
    "\n",
    "search_job=driver.find_element_by_id(\"sc.keyword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the element for job location by id\n",
    "search_location=driver.find_element_by_id(\"sc.location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click using xpath function\n",
    "click_search=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "click_search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Then scrape the data for the first 10 jobs results you get in the above shown\n",
    "page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"ad17267f-3989-4c92-b701-a5430c33e941\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"6930d722-dc1c-4acd-b19e-24cf648ba507\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"c5328ea8-d42f-4101-b7ea-e5ad520ad0e0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"586af394-47cd-40c4-a672-bd8dc2ac7d48\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"e8f1421f-b67d-4d15-be54-784cef42f4ca\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"02fbca08-4978-4324-8099-8239f3792610\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"d4c910fe-cdb9-4c4d-9eab-5b515d00c00f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"6c4ba995-a286-446f-afe3-78d0c9c0b168\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"137a900e-c37e-48d9-97cb-a456c997fc16\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"c15f1999-a520-4765-8fa0-3d17b84dbbb1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"54cde52f-df6c-413c-9042-d043494d43fe\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"fd7d1d90-dab4-4691-9082-572dcfb0446e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"32b48382-484c-41d6-a6b1-089683230cdb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"f5dcfa81-724a-4339-86ae-4d6c4922c9ff\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"37901511-6016-4d3d-89c3-f849e32334b1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"03ca39cd-67b4-4b04-a442-adffd35efc3d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"ff9a3ac0-e510-4e1c-8198-0b9b16886436\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"8771801f-4c79-4d7f-a19f-65e24a0aaea1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"3120288d-4c9d-4853-b791-381cd76312b4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"c398f309-f5c7-4e74-b22f-854b1affaa91\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"a522e171-e04f-4d55-9c82-d5afd5a01c4c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"47108cf2-5d95-428d-9c4b-4aff309dd3b7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"53826542-6b89-415f-999c-e26632bccc6e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"e8b67b0e-a74d-4a42-8afe-ff676632c7d9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"22777f60-97fe-4507-a752-2f9ef4cfa535\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"1b047cc4-a923-460c-9b7b-ad5528717429\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"b7976f0a-7022-4bb2-8bde-84fe0aec09c5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"b4bc6677-5157-40ba-9b47-3336a7152cf0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"135354ee-5828-41f0-b844-62fc6b174f29\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"609d0511-6141-46cd-83ce-33181561534d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"cc937e21-c213-4090-abf2-e2b56d220fcc\")>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to scrape company_name, No. of days ago when job was posted, Rating of the company data we'll get its tags first by using xpath\n",
    "\n",
    "#firstly we'll extract the tags for company_name.\n",
    "\n",
    "comp_tags=driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']\")\n",
    "\n",
    "comp_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bechtel',\n",
       " 'Mansha Solutions',\n",
       " 'Ericsson',\n",
       " 'Lantern Digital Services',\n",
       " 'Priority Vendor',\n",
       " 'Sparkbpl',\n",
       " 'Gauge Data Solutions',\n",
       " 'Siemens Technology and Services Private Limited',\n",
       " 'xtLytics',\n",
       " 'Skyjobs hr services']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we'll extract all the tags having the job titles using for loop\n",
    "companies=[]\n",
    "for i in comp_tags[:10]:\n",
    "    companies.append(i.text)\n",
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"ac2b2279-57ef-4e9a-a23a-77a8323faa7e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"00d53bd1-c46b-44dc-a0d2-cfd7081bde32\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"6e714392-45b9-4922-803f-c1c54df3caab\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"053166b1-7438-45f4-bfa9-7388b0a29a16\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"20337ce7-0f08-45b9-a223-5bccccf3b898\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"acd7769b-ca80-4cfb-8e9d-946aab4e77bf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"f883cc73-bdb7-439d-9bad-cbf4cfbd46a7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"fc37d3b2-5b24-45d8-8e76-f66a3046bcb0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"a477ab2a-1747-4d8d-9a0d-b0041b530a7f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"ecdea82d-e080-4d6b-8c4c-be0506b8be92\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"4b0d4805-9d56-47c5-a5ff-8f6386ebd547\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"640f6973-e91b-4163-b413-d1d25138d901\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"eec83644-5397-4347-babb-2d71ba35ba56\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"135a3b9d-2a64-47c2-aab6-877068e239e4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"e9d93747-e7da-4bf9-8fce-a1e28dfed79e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"6578a782-b9dd-40ec-bfc6-cfbfc88eee30\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"7b5350a7-f712-43ec-a7f3-7417d4e832e8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"01f4dbce-e519-46dd-962a-999886c4a6a5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"49c8f55a-75ef-4c89-9118-162d8a0f3c9d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"ebfabfe9-c0d6-4e0b-a7c0-368e0ac97622\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"c08ed095-cdc3-400c-8115-3b896bcddbcb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"43954de0-75c3-4338-b5b6-09c35aa97125\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"4f0c1ce0-5a88-4a05-9e62-077c309f4e92\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"7fb86e8c-36da-42eb-a10c-2168bf138545\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"5c71a535-8dd5-498a-917c-bab367714d1f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"d2c7ad18-f67c-48be-9488-e1a29d9fdfa9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"57de44a2-3d4e-4c21-aa5d-1f5c470c8061\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"97c75b6a-0fb4-404a-b1e6-fc3eed707301\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"ee7f3cdd-499e-4c9a-a7b2-692d033af600\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"7b3507e9-4c47-45c4-9f8e-247336c18561\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"274af194-a414-4e85-8133-73299f784499\")>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we'll extract the tags for No. of days ago when job was posted.\n",
    "\n",
    "days_ago_tags=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "\n",
    "days_ago_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16d', '9d', '24h', '7d', '13d', '13d', '13d', '1d', '24h', '6d']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we'll extract all the tags having the job titles using for loop\n",
    "no_days=[]\n",
    "for i in days_ago_tags[:10]:\n",
    "    no_days.append(i.text)\n",
    "no_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"c2398baa-757d-412b-9ec3-3958d55fb84b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"57b26d70-b918-4104-883a-bbb77171588e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"5f8cf60f-0d52-4411-86ad-006df45e322b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"7429d484-f236-40b8-892d-c56ba4894259\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"6618d0a1-1d53-4e35-99d4-e3b345417d94\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"c0f15406-8ce3-432b-8481-e752579482b2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"ae09d338-2773-47b8-afa9-b43edca52e26\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"b1af0981-9e74-4103-9265-c79c04242fff\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"a4ed2edc-2172-4fff-b05b-0998727d37e2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"d1f46ffc-f2af-42a4-a9c6-ba56c88c588f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"4a4d8974-64af-4eae-a760-eff3aa7c5b09\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"2ff86a44-45e0-4acb-aef3-ca068de11c76\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"892707a4-be05-4c31-a1d2-22b28ccf6790\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"464ed042-87bf-4a24-b3e8-6839d7e97dc3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"faf646c8-346a-4749-95f6-a1b3b032e6db\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"f1607d6e-58cd-410d-b335-af7838498105\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"ccd6be17-fb6d-42c6-b485-2d870741d67b\")>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we'll extract the tags for Rating of the company.\n",
    "\n",
    "comp_rating=driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "\n",
    "comp_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.0', '4.1', '3.7', '3.1', '4.1', '4.3', '4.1', '3.8', '5.0', '3.8']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we'll extract all the tags having the job titles using for loop\n",
    "ratings=[]\n",
    "for i in comp_rating[:10]:\n",
    "    ratings.append(i.text)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>no. of days job posted</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bechtel</td>\n",
       "      <td>16d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mansha Solutions</td>\n",
       "      <td>9d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lantern Digital Services</td>\n",
       "      <td>7d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>13d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sparkbpl</td>\n",
       "      <td>13d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>13d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>1d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xtLytics</td>\n",
       "      <td>24h</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Skyjobs hr services</td>\n",
       "      <td>6d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Company Name no. of days job posted  \\\n",
       "0                                          Bechtel                    16d   \n",
       "1                                 Mansha Solutions                     9d   \n",
       "2                                         Ericsson                    24h   \n",
       "3                         Lantern Digital Services                     7d   \n",
       "4                                  Priority Vendor                    13d   \n",
       "5                                         Sparkbpl                    13d   \n",
       "6                             Gauge Data Solutions                    13d   \n",
       "7  Siemens Technology and Services Private Limited                     1d   \n",
       "8                                         xtLytics                    24h   \n",
       "9                              Skyjobs hr services                     6d   \n",
       "\n",
       "  Ratings  \n",
       "0     4.0  \n",
       "1     4.1  \n",
       "2     3.7  \n",
       "3     3.1  \n",
       "4     4.1  \n",
       "5     4.3  \n",
       "6     4.1  \n",
       "7     3.8  \n",
       "8     5.0  \n",
       "9     3.8  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we got complete solution of ques.4 \n",
    "import pandas as pd\n",
    "glassdoor = pd.DataFrame({})\n",
    "glassdoor[\"Company Name\"] = companies[:10]\n",
    "glassdoor[\"no. of days job posted\"] = no_days[:10]\n",
    "glassdoor[\"Ratings\"] = ratings[:10]\n",
    "glassdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the url  https://www.glassdoor.co.in/Salaries/index.htm\n",
    "url=\"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "search_job=driver.find_element_by_id(\"KeywordSearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the element for job location by id\n",
    "search_location=driver.find_element_by_id(\"LocationSearch\")\n",
    "\n",
    "search_location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click using xpath function\n",
    "click_search=driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "click_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are on the job salaries webpage thus we can Scrape data for first 10 companies. Scrape the min salary, no. of salaries, max salary, companyname, Average salary and rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the min/max salaries by finding the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"7ebfed57-f090-4329-abf2-8d94703aa127\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"9509dbd0-bf79-466d-b52a-c4945dfee776\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"74671c10-115c-418f-a48d-b61092a9f41c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"d14c6d90-3b4a-48b6-a53a-e7b59b07d7fc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"a95559a5-9102-4f96-9ed3-fdf0d43e5ed5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"34333bd5-e9c5-4c5d-9108-0a73c05882cd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"b10e65b7-1be5-4ac1-8263-e98bc3c8e016\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"53c8e314-cfa7-4fb7-8f19-0cbe0f2ddbcf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"e9c3da19-2c36-4ab0-8f6c-23fd45469980\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"98f7e074-0e01-47ba-9d70-d37707cebd78\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"0a0142c1-7f43-4181-aafe-eabcf6e59e9f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"a45a6aa8-1d15-41a5-af57-91ab28f713b6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"98db831a-61a2-4e22-838e-d2c7e7e2229f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"0e9ca22b-3db0-4c8f-bdab-69690a4262e9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"608a9810-3153-420a-8cab-79ab67eae57e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"ba0ffe53-c9b1-4a79-b646-71ce1a5171d7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"9cd7beba-dda8-47e5-b04d-29780634b3df\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"c70cc5e4-39ef-4a53-9f03-9c5bbbdd4867\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"74389f6f-5710-4632-b38c-2f49b55ac967\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"9bfea15c-1d9a-42e5-a2bb-d18466598ac8\")>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sal_tags=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__rangeBar undefined undefined ']\")\n",
    "\n",
    "sal_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹126K\\n₹1,303K',\n",
       " '₹112K\\n₹3,719K',\n",
       " '₹55K\\n₹8,565K',\n",
       " '₹47K\\n₹5,170K',\n",
       " '₹102K\\n₹4,115K',\n",
       " '₹111K\\n₹10,576K',\n",
       " '₹160K\\n₹7,090K',\n",
       " '₹76K\\n₹1,968K',\n",
       " '₹106K\\n₹1,914K',\n",
       " '₹162K\\n₹5,039K']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sal=[]\n",
    "for i in sal_tags[:10]:\n",
    "    sal.append(i.text)\n",
    "sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹1,303K',\n",
       " '₹3,719K',\n",
       " '₹8,565K',\n",
       " '₹5,170K',\n",
       " '₹4,115K',\n",
       " '₹10,576K',\n",
       " '₹7,090K',\n",
       " '₹1,968K',\n",
       " '₹1,914K',\n",
       " '₹5,039K']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we'll extract all the tags having the salaries using for loop\n",
    "min_sal=[]\n",
    "max_sal=[]\n",
    "for i in sal_tags[:10]:\n",
    "    min_sal.append(i.text.strip().split('\\n')[0].strip())\n",
    "    max_sal.append(i.text.strip().split('\\n')[1].strip())\n",
    "min_sal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹1,303K',\n",
       " '₹3,719K',\n",
       " '₹8,565K',\n",
       " '₹5,170K',\n",
       " '₹4,115K',\n",
       " '₹10,576K',\n",
       " '₹7,090K',\n",
       " '₹1,968K',\n",
       " '₹1,914K',\n",
       " '₹5,039K']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"c42cf583-ffbc-498a-8161-4098cf77380f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"2917300c-aa69-4087-9230-74b00456e636\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"13d911d9-c4c4-497b-baf9-ddb1ff3dd1c8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"15805839-b2a9-4157-a84f-3744bb708192\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"daa4cd77-411b-482a-be90-b4fc55454e10\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"2c4c0d35-669c-43e0-9796-50cb0d94f88c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"6bec1568-b648-4387-902e-f9d85ab7865d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"2b711ea0-4277-40f5-bf63-102d86b951af\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"41225a64-2aef-46b6-9f5a-8ebf32918869\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"81475776-32de-412d-b783-95dfb00169a2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"8a4a2967-8b6a-45a1-a3ef-14770911ae19\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"19ff5db4-a884-40d5-bee9-a1ec03979a94\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"6841b46b-ec69-4c0a-a2f2-dd292d5c1919\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"841b5c3d-c087-47d1-b4bc-dd2db05616ba\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"28229014-f176-45c9-8f52-b9669c40389f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"937aeac6-ffa5-496e-b906-a00c3f18fdb2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"315fecb3-bce1-456e-b9bc-dc3875660800\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"1d83953d-7411-46a9-bdb5-81edba885c80\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"264be7c7-8c19-42cb-b766-3e09450c6720\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"a96f7e18-ba99-450e-af8b-a2b527497c41\")>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the average salaries\n",
    "Avgsal_tags=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']\")\n",
    "\n",
    "Avgsal_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 3,75,013/yr',\n",
       " '₹ 4,39,846/yr',\n",
       " '₹ 6,53,247/yr',\n",
       " '₹ 4,53,695/yr',\n",
       " '₹ 4,40,335/yr',\n",
       " '₹ 10,46,377/yr',\n",
       " '₹ 6,14,020/yr',\n",
       " '₹ 8,08,205/yr',\n",
       " '₹ 2,19,348/yr',\n",
       " '₹ 6,00,000/yr']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the required data from above tags\n",
    "avg_sal=[]\n",
    "for i in Avgsal_tags[:10]:\n",
    "    avg_sal.append(i.text.replace('\\n',''))\n",
    "    \n",
    "avg_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"ac2727b9-9c8d-4af3-b046-6ca1695de08f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"e695b31e-9a91-4793-9f45-2284f6344ba0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"575b9588-bbdf-4101-943c-8e23121e3945\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"44a5a9ba-372c-41f3-9ede-4d1c02ec0adf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"5eb281ba-51d8-4efb-81c9-fe8f0ba3e6f8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"6a723cfb-58be-46d6-9e06-7cf707c3830c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"d4d62967-a7fb-4fd4-b806-95d81db00ba3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"be7ddbdc-0865-4de7-9ee2-bb2b03e87b76\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"6092500d-990c-412d-a992-fdf846e6fb29\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"a9e48e4e-3836-4933-b521-1663db73ffe4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"1050c9ea-0c94-48e2-a66e-ed92a96c58e1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"0c5e90da-8d47-4b86-a37c-87901915191e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"e371d589-5b1d-43dc-b9eb-fdfec1e63a7a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"76cafc98-f21a-4ea7-b5b8-a9c54131f4a4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"77bb5a12-72f9-43d6-bc02-60ab21e97314\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"dff29009-53a1-425d-8c41-f9307074bc33\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"997266fa-b253-4128-b795-8d995a0be043\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"249d41d4-6d0e-446e-bb8d-c409dc1d3bb2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"97b4b187-4db7-4fd7-a23e-b85bb248c9c9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"0d66cd64-d720-4159-95b2-548b9126d991\")>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the no. of  salaries by finding the tags\n",
    "\n",
    "no_sal_tags=driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\")\n",
    "\n",
    "no_sal_tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,277 salaries',\n",
       " '601 salaries',\n",
       " '574 salaries',\n",
       " '426 salaries',\n",
       " '384 salaries',\n",
       " '371 salaries',\n",
       " '359 salaries',\n",
       " '354 salaries',\n",
       " '338 salaries',\n",
       " '336 salaries']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_salaries=[]\n",
    "for i in no_sal_tags[:10]:\n",
    "    no_salaries.append(i.text)\n",
    "no_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"7638fabf-16f1-432c-9d33-9a7501207f9a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"dbd2bf73-58dd-4737-bf0e-076c02f243cb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"42f05474-0d8e-4f98-806a-e4355fc3606a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"cc3f16f9-6124-4382-b347-04c5bcbc40e7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"2b11d202-47a1-45af-8852-dd314c04b96d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"78a50655-9771-4246-ac4f-bd944f6683aa\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"67eca48b-5585-47df-9b14-cf6a0ff6ee4c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"f2f03b79-0f23-4c71-a2be-563fb268af15\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"bc177f45-2d42-4b7f-a851-73e945eebb46\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"fc26a715-c492-4d2f-a5ae-7cb401271ff6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"979831bb-1ab1-44c0-9a50-c5aa4eb4a953\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"71fd161a-1a5b-4eec-95f7-003f17d37217\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"6404b023-80f1-446e-b9a0-18ba291302e6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"44703374-2bb6-4028-87c5-d37ae507db9b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"46d5b0f9-922a-4a01-af20-e8a68b0565d4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"87a391b1-0968-405a-92be-05c619034e95\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"e6be35e2-c7df-47d2-8c6d-73048c7cf780\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"7d973649-e89b-4e44-808f-b5d19825c5a1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"4bc1eb4f-744e-4a5d-975d-1dfd3031e180\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"36255da53f41f251d2681218f20777a6\", element=\"227e5db6-b607-40f9-aadd-9ec0ac0a1ba2\")>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the companies name by finding the tags\n",
    "comp_tags=driver.find_elements_by_xpath(\"//div[@data-test='job-info']\")\n",
    "\n",
    "comp_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tata Consultancy Services',\n",
       " 'HCL Technologies',\n",
       " 'Tata Consultancy Services',\n",
       " 'Capgemini Engineering',\n",
       " 'Tata Consultancy Services',\n",
       " 'Deloitte',\n",
       " 'HCL Technologies',\n",
       " 'Capgemini Engineering',\n",
       " 'Genpact',\n",
       " 'Evalueserve']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_names=[]\n",
    "for i in comp_tags[:10]:\n",
    "    companies_names.append(i.text.strip().split('\\n')[1])\n",
    "companies_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AS we got all required data now will create the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of Salaries</th>\n",
       "      <th>Average Salaries</th>\n",
       "      <th>Min Salaries</th>\n",
       "      <th>Max Salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>2,277 salaries</td>\n",
       "      <td>₹ 3,75,013/yr</td>\n",
       "      <td>₹126K</td>\n",
       "      <td>₹1,303K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>601 salaries</td>\n",
       "      <td>₹ 4,39,846/yr</td>\n",
       "      <td>₹112K</td>\n",
       "      <td>₹3,719K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>574 salaries</td>\n",
       "      <td>₹ 6,53,247/yr</td>\n",
       "      <td>₹55K</td>\n",
       "      <td>₹8,565K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Capgemini Engineering</td>\n",
       "      <td>426 salaries</td>\n",
       "      <td>₹ 4,53,695/yr</td>\n",
       "      <td>₹47K</td>\n",
       "      <td>₹5,170K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>384 salaries</td>\n",
       "      <td>₹ 4,40,335/yr</td>\n",
       "      <td>₹102K</td>\n",
       "      <td>₹4,115K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>371 salaries</td>\n",
       "      <td>₹ 10,46,377/yr</td>\n",
       "      <td>₹111K</td>\n",
       "      <td>₹10,576K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>359 salaries</td>\n",
       "      <td>₹ 6,14,020/yr</td>\n",
       "      <td>₹160K</td>\n",
       "      <td>₹7,090K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Capgemini Engineering</td>\n",
       "      <td>354 salaries</td>\n",
       "      <td>₹ 8,08,205/yr</td>\n",
       "      <td>₹76K</td>\n",
       "      <td>₹1,968K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>338 salaries</td>\n",
       "      <td>₹ 2,19,348/yr</td>\n",
       "      <td>₹106K</td>\n",
       "      <td>₹1,914K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Evalueserve</td>\n",
       "      <td>336 salaries</td>\n",
       "      <td>₹ 6,00,000/yr</td>\n",
       "      <td>₹162K</td>\n",
       "      <td>₹5,039K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name No. of Salaries Average Salaries Min Salaries  \\\n",
       "0  Tata Consultancy Services  2,277 salaries    ₹ 3,75,013/yr        ₹126K   \n",
       "1           HCL Technologies    601 salaries    ₹ 4,39,846/yr        ₹112K   \n",
       "2  Tata Consultancy Services    574 salaries    ₹ 6,53,247/yr         ₹55K   \n",
       "3      Capgemini Engineering    426 salaries    ₹ 4,53,695/yr         ₹47K   \n",
       "4  Tata Consultancy Services    384 salaries    ₹ 4,40,335/yr        ₹102K   \n",
       "5                   Deloitte    371 salaries   ₹ 10,46,377/yr        ₹111K   \n",
       "6           HCL Technologies    359 salaries    ₹ 6,14,020/yr        ₹160K   \n",
       "7      Capgemini Engineering    354 salaries    ₹ 8,08,205/yr         ₹76K   \n",
       "8                    Genpact    338 salaries    ₹ 2,19,348/yr        ₹106K   \n",
       "9                Evalueserve    336 salaries    ₹ 6,00,000/yr        ₹162K   \n",
       "\n",
       "  Max Salaries  \n",
       "0      ₹1,303K  \n",
       "1      ₹3,719K  \n",
       "2      ₹8,565K  \n",
       "3      ₹5,170K  \n",
       "4      ₹4,115K  \n",
       "5     ₹10,576K  \n",
       "6      ₹7,090K  \n",
       "7      ₹1,968K  \n",
       "8      ₹1,914K  \n",
       "9      ₹5,039K  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we got complete solution of ques.5 ; store the data in a dataframe.\n",
    "import pandas as pd\n",
    "job_salaries = pd.DataFrame({})\n",
    "job_salaries[\"Company Name\"] = companies_names[:10]\n",
    "job_salaries[\"No. of Salaries\"] = no_salaries[:10]\n",
    "job_salaries[\"Average Salaries\"] = avg_sal[:10]\n",
    "job_salaries[\"Min Salaries\"] = min_sal[:10]\n",
    "job_salaries[\"Max Salaries\"] = max_sal[:10]\n",
    "job_salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Pooja.Mishra\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipkart=\"https://www.flipkart.com/\"\n",
    "driver.get(flipkart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Enter “sunglasses” in the search field where “search for products, brands and\n",
    "more” is written and click the search icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sunglasses=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sunglasses.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search icon\n",
    "flip_search=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "flip_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "#Using loop we can get all data as required\\n\",\n",
    "i=0\n",
    "count = 0\n",
    "sunglass_brandData=[]\n",
    "sunglasses_descData=[]\n",
    "sunglasses_discountData=[]\n",
    "sunglasses_PriceData=[]\n",
    "\n",
    "while i <=100:\n",
    "    try:\n",
    "        \n",
    "        count = len(sunglass_brandData)\n",
    "        if count == 0:\n",
    "            #Exctracting the all data from page with xpath attributes\n",
    "            #Begin\n",
    "            sunglass_brand_elements=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "            for i in sunglass_brand_elements:\n",
    "                sunglass_brandData.append(i.text)\n",
    "            sunglasses_desc_elements=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "            for j in sunglasses_desc_elements:\n",
    "                sunglasses_descData.append(j.text) \n",
    "            sunglasses_discount_elements=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "            for k in sunglasses_discount_elements:\n",
    "                sunglasses_discountData.append(k.text)\n",
    "            sunglasses_price_elements=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "            for l in sunglasses_price_elements:\n",
    "                sunglasses_PriceData.append(l.text)\n",
    "            #End   \n",
    "            count = len(sunglass_brandData)\n",
    "            i = len(sunglass_brandData)\n",
    "            if count<=40:\n",
    "                next_page_click=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "                next_page_click.click()\n",
    "                time.sleep(3)\n",
    "        if  count <= 100:\n",
    "            #Exctracting the all data from page with xpath attributes\\n\",\n",
    "            #Begin\n",
    "            sunglass_brand_elements=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "            for i in sunglass_brand_elements:\n",
    "                sunglass_brandData.append(i.text)\n",
    "            sunglasses_desc_elements=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "            for j in sunglasses_desc_elements:\n",
    "                sunglasses_descData.append(j.text) \n",
    "            sunglasses_discount_elements=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "            for k in sunglasses_discount_elements:\n",
    "                sunglasses_discountData.append(k.text)\n",
    "            sunglasses_price_elements=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "            for l in sunglasses_price_elements:\n",
    "                sunglasses_PriceData.append(l.text)\n",
    "            #End  \n",
    "            count = len(sunglass_brandData)\n",
    "            i = len(sunglass_brandData)\n",
    "            next_page_click=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")[1]\n",
    "            next_page_click.click()\n",
    "            time.sleep(3)\n",
    "        if i >=100 :\n",
    "            break;\n",
    "        i+=1 \n",
    "    except NoSuchElementException as e:\n",
    "        sunglass_brandData.append('-')\n",
    "print (len(sunglass_brandData))\n",
    "print (len(sunglasses_discountData))\n",
    "print (len(sunglasses_PriceData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "print (len(sunglasses_descData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Sunglasses Desc</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>21% off</td>\n",
       "      <td>₹627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fravy</td>\n",
       "      <td>UV Protection, Gradient, Night Vision Retro Sq...</td>\n",
       "      <td>83% off</td>\n",
       "      <td>₹329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (F...</td>\n",
       "      <td>77% off</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Retro Square, Wayfarer Sunglasse...</td>\n",
       "      <td>70% off</td>\n",
       "      <td>₹314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (60)</td>\n",
       "      <td>71% off</td>\n",
       "      <td>₹419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (55)</td>\n",
       "      <td>20% off</td>\n",
       "      <td>₹6,792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Dannilo</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>78% off</td>\n",
       "      <td>₹218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Mirrored Aviator Sunglasses (58)</td>\n",
       "      <td>30% off</td>\n",
       "      <td>₹3,843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (56)</td>\n",
       "      <td>75% off</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Riding Glasses Wayfarer Sunglas...</td>\n",
       "      <td>73% off</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                    Sunglasses Desc  \\\n",
       "0         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "1            Fravy  UV Protection, Gradient, Night Vision Retro Sq...   \n",
       "2   ROZZETTA CRAFT  Polarized, UV Protection Aviator Sunglasses (F...   \n",
       "3            NuVew  UV Protection Retro Square, Wayfarer Sunglasse...   \n",
       "4            NuVew              UV Protection Cat-eye Sunglasses (60)   \n",
       "..             ...                                                ...   \n",
       "95         Ray-Ban         UV Protection Retro Square Sunglasses (55)   \n",
       "96         Dannilo  UV Protection, Gradient Rectangular Sunglasses...   \n",
       "97         Ray-Ban                   Mirrored Aviator Sunglasses (58)   \n",
       "98  ROZZETTA CRAFT          UV Protection Rectangular Sunglasses (56)   \n",
       "99       ROYAL SON  UV Protection, Riding Glasses Wayfarer Sunglas...   \n",
       "\n",
       "   Discount   Price  \n",
       "0   21% off    ₹627  \n",
       "1   83% off    ₹329  \n",
       "2   77% off    ₹449  \n",
       "3   70% off    ₹314  \n",
       "4   71% off    ₹419  \n",
       "..      ...     ...  \n",
       "95  20% off  ₹6,792  \n",
       "96  78% off    ₹218  \n",
       "97  30% off  ₹3,843  \n",
       "98  75% off    ₹499  \n",
       "99  73% off    ₹399  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we got complete solution of ques.6 ; store the data in a dataframe.\n",
    "import pandas as pd\n",
    "sunglasses = pd.DataFrame({})\n",
    "sunglasses[\"Brand Name\"] = sunglass_brandData[:100]\n",
    "sunglasses[\"Sunglasses Desc\"] = sunglasses_descData[:100]\n",
    "sunglasses[\"Discount\"] = sunglasses_discountData[:100]\n",
    "sunglasses[\"Price\"] = sunglasses_PriceData[:100]\n",
    "sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7. Scrape 100 reviews data from flipkart.com for iphone11 phone. \n",
    "    You have to go the link:\n",
    "    https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#Connecting to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Pooja.Mishra\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "driver.get(iphone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Scrape the review rating, review summary and full summary for 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see only 1 review thus will click on more reviews option\n",
    "more_reviews=driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "more_reviews.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping required data of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "count = 0\n",
    "review_rating=[]\n",
    "review_summary=[]\n",
    "full_summary=[]\n",
    "\n",
    "while i <=100:\n",
    "    try:\n",
    "        \n",
    "            count = len(review_rating)\n",
    "            if count == 0:\n",
    "                #Exctracting the all data from page with xpath attributes\n",
    "                #Begin           \n",
    "                review_rating_elements=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")          \n",
    "                for i in review_rating_elements:\n",
    "                    review_rating.append(i.text)\n",
    "                review_summary_elements=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "                for j in review_summary_elements:\n",
    "                    review_summary.append(j.text) \n",
    "                full_summary_elements=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "                for k in full_summary_elements:\n",
    "                    full_summary.append(k.text)\n",
    "           \n",
    "               #End   \n",
    "                count = len(review_rating)\n",
    "                i = len(review_rating)\n",
    "                if count<=10:\n",
    "                    next_page_click=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "                    next_page_click.click()\n",
    "                    time.sleep(3)\n",
    "            if  count <= 100:\n",
    "                #Exctracting the all data from page with xpath attributes\n",
    "                #Begin\n",
    "                review_rating_elements=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "                for i in review_rating_elements:\n",
    "                    review_rating.append(i.text)\n",
    "                review_summary_elements=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "                for j in review_summary_elements:\n",
    "                    review_summary.append(j.text) \n",
    "                full_summary_elements=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "                for k in full_summary_elements:\n",
    "                    full_summary.append(k.text)\n",
    "                #End  \n",
    "                count = len(review_rating)\n",
    "                i = len(review_rating)\n",
    "                next_page_click=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "                next_page_click.click()\n",
    "                time.sleep(3)\n",
    "            if i >=100 :\n",
    "                break;\n",
    "            i+=1 \n",
    "    except NoSuchElementException as e:\n",
    "        review_rating.append('-')\n",
    "                                                         \n",
    "                                                         \n",
    "                                                            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print (len(review_rating))\n",
    "print (len(review_summary))\n",
    "print (len(full_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Superb Product !!!\\nA big and worthy upgrade f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review Rating      Review Summary  \\\n",
       "0              5           Brilliant   \n",
       "1              5    Perfect product!   \n",
       "2              5       Great product   \n",
       "3              5   Worth every penny   \n",
       "4              4         Good choice   \n",
       "..           ...                 ...   \n",
       "95             5            Terrific   \n",
       "96             5  Highly recommended   \n",
       "97             5           Wonderful   \n",
       "98             5      Classy product   \n",
       "99             5           Brilliant   \n",
       "\n",
       "                                         Full Summary  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  Really worth of money. i just love it. It is t...  \n",
       "96  It's my first time to use iOS phone and I am l...  \n",
       "97  This is my first ever I phone. Before this I w...  \n",
       "98  Superb Product !!!\\nA big and worthy upgrade f...  \n",
       "99  I have migrated from OP 7pro... and trust me, ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we got complete solution of ques.7 ; displaying the data in a dataframe.\n",
    "import pandas as pd\n",
    "reviews_list = pd.DataFrame({})\n",
    "reviews_list[\"Review Rating\"] = review_rating[:100]\n",
    "reviews_list[\"Review Summary\"] = review_summary[:100]\n",
    "reviews_list[\"Full Summary\"] = full_summary[:100]\n",
    "reviews_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\\\Users\\\\Pooja.Mishra\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the web page\n",
    "sneakers=\"https://www.flipkart.com/\"\n",
    "driver.get(sneakers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Enter “sneakers” in the search field where “search for products, brands and more” is written and click the search icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_button.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search icon\n",
    "search=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now scraping the data for product description, Price, Discount % and Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "118\n",
      "120\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Using loop we can get all data as required\\n\",\n",
    "i=0\n",
    "count = 0\n",
    "sneakers_brandData=[]\n",
    "sneakers_descData=[]\n",
    "sneakers_discountData=[]\n",
    "sneakers_PriceData=[]\n",
    "\n",
    "while i <=100:\n",
    "    try:\n",
    "        \n",
    "        count = len(sneakers_brandData)\n",
    "        if count == 0:\n",
    "            #Exctracting the all data from page with xpath attributes\n",
    "            #Begin\n",
    "            sneakers_brand_elements=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "            for i in sneakers_brand_elements:\n",
    "                sneakers_brandData.append(i.text)\n",
    "            sneakers_desc_elements=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "            for j in sneakers_desc_elements:\n",
    "                sneakers_descData.append(j.text) \n",
    "            sneakers_discount_elements=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "            for k in sneakers_discount_elements:\n",
    "                sneakers_discountData.append(k.text)\n",
    "            sneakers_price_elements=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "            for l in sneakers_price_elements:\n",
    "                sneakers_PriceData.append(l.text)\n",
    "            #End   \n",
    "            count = len(sneakers_brandData)\n",
    "            i = len(sneakers_brandData)\n",
    "            if count<=40:\n",
    "                next_page_click=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "                next_page_click.click()\n",
    "                time.sleep(3)\n",
    "        if  count <= 100:\n",
    "            #Exctracting the all data from page with xpath attributes\\n\",\n",
    "            #Begin\n",
    "            sneakers_brand_elements=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "            for i in sneakers_brand_elements:\n",
    "                sneakers_brandData.append(i.text)\n",
    "            sneakers_desc_elements=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "            for j in sneakers_desc_elements:\n",
    "                sneakers_descData.append(j.text) \n",
    "            sneakers_discount_elements=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "            for k in sneakers_discount_elements:\n",
    "                sneakers_discountData.append(k.text)\n",
    "            sneakers_price_elements=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "            for l in sneakers_price_elements:\n",
    "                sneakers_PriceData.append(l.text)\n",
    "            #End  \n",
    "            count = len(sneakers_brandData)\n",
    "            i = len(sneakers_brandData)\n",
    "            next_page_click=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")[1]\n",
    "            next_page_click.click()\n",
    "            time.sleep(3)\n",
    "        if i >=100 :\n",
    "            break;\n",
    "        i+=1 \n",
    "    except NoSuchElementException as e:\n",
    "        sneakers_brandData.append('-')\n",
    "print (len(sneakers_brandData))\n",
    "print (len(sneakers_discountData))\n",
    "print (len(sneakers_PriceData))\n",
    "print (len(sneakers_descData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Desc</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>47% off</td>\n",
       "      <td>₹1,924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>67% off</td>\n",
       "      <td>₹1,199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>62% off</td>\n",
       "      <td>₹379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>52% off</td>\n",
       "      <td>₹474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>60% off</td>\n",
       "      <td>₹398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>LEATHERKRAFT</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>66% off</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GUSTO</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>40% off</td>\n",
       "      <td>₹699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Englewood</td>\n",
       "      <td>Men's White Suede Leather Lace-Up High Ankle C...</td>\n",
       "      <td>49% off</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>52% off</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Black Mesh Sneakers for Men Sneakers For Men</td>\n",
       "      <td>50% off</td>\n",
       "      <td>₹1,813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                       Product Desc Discount  \\\n",
       "0         DUCATI                                   Sneakers For Men  47% off   \n",
       "1         DUCATI                                   Sneakers For Men  67% off   \n",
       "2   Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men  62% off   \n",
       "3   Robbie jones                                   Sneakers For Men  52% off   \n",
       "4        Numenzo                                   Sneakers For Men  60% off   \n",
       "..           ...                                                ...      ...   \n",
       "95  LEATHERKRAFT                                   Sneakers For Men  66% off   \n",
       "96         GUSTO  Casual , Partywear Sneakers Shoes For Men's An...  40% off   \n",
       "97     Englewood  Men's White Suede Leather Lace-Up High Ankle C...  49% off   \n",
       "98      HOTSTYLE                                   Sneakers For Men  52% off   \n",
       "99        DUCATI       Black Mesh Sneakers for Men Sneakers For Men  50% off   \n",
       "\n",
       "     Price  \n",
       "0   ₹1,924  \n",
       "1   ₹1,199  \n",
       "2     ₹379  \n",
       "3     ₹474  \n",
       "4     ₹398  \n",
       "..     ...  \n",
       "95    ₹299  \n",
       "96    ₹699  \n",
       "97    ₹499  \n",
       "98    ₹299  \n",
       "99  ₹1,813  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we got complete solution of ques.8 ; displaying the data in a dataframe.\n",
    "import pandas as pd\n",
    "sneakers_list = pd.DataFrame({})\n",
    "sneakers_list[\"Brand\"] = sneakers_brandData[:100]\n",
    "sneakers_list[\"Product Desc\"] = sneakers_descData[:100]\n",
    "sneakers_list[\"Discount\"] = sneakers_discountData[:100]\n",
    "sneakers_list[\"Price\"] = sneakers_PriceData[:100]\n",
    "sneakers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9.Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, And then scrape First 100 shoes data you get. The data should include “Brand” of\n",
    "the shoes , Short Shoe description, price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\\\Users\\\\Pooja.Mishra\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the myntra url\n",
    "myntra=\"https://www.myntra.com/shoes\"\n",
    "driver.get(myntra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on filter 'Price' & 'color' to scrape required data\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "try:\n",
    "        \n",
    "        color_filter=driver.find_elements_by_xpath(\"//li[@class='colour-listItem']\")\n",
    "        color_filter\n",
    "        for i in color_filter:\n",
    "            if \"Black\" in i.text:\n",
    "                i.click()\n",
    "\n",
    "        price_filter=driver.find_elements_by_xpath(\"//ul[@class='price-list']/li\")\n",
    "        price_filter\n",
    "        for i in price_filter:\n",
    "            if \"Rs. 6649 to Rs. 13099\" in i.text:\n",
    "                i.click()\n",
    "except NoSuchElementException:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we are on desired webpage with filters applied so now we'll scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "count = 0\n",
    "shoes_Brand=[]\n",
    "shoes_Desc=[]\n",
    "shoes_Price=[]\n",
    "\n",
    "while i <=100:\n",
    "    try:\n",
    "        \n",
    "            count = len(shoes_Brand)\n",
    "            if count == 0:\n",
    "                #Exctracting the all data from page with xpath attributes\n",
    "                #Begin           \n",
    "                shoes_Brand_elements=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")          \n",
    "                for i in shoes_Brand_elements:\n",
    "                    shoes_Brand.append(i.text)\n",
    "                shoes_Desc_elements=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "                for j in shoes_Desc_elements:\n",
    "                    shoes_Desc.append(j.text) \n",
    "                shoes_Price_elements=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "                for k in shoes_Price_elements:\n",
    "                    shoes_Price.append(k.text)\n",
    "           \n",
    "               #End   \n",
    "                count = len(shoes_Brand)\n",
    "                i = len(shoes_Brand)\n",
    "                if count<=50:\n",
    "                    next_page_click=driver.find_element_by_xpath(\"//li[@class='pagination-next']\")\n",
    "                    next_page_click.click()\n",
    "                    time.sleep(3)\n",
    "            if  count <= 100:\n",
    "                #Exctracting the all data from page with xpath attributes\n",
    "                #Begin\n",
    "                shoes_Brand_elements=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")          \n",
    "                for i in shoes_Brand_elements:\n",
    "                    shoes_Brand.append(i.text)\n",
    "                shoes_Desc_elements=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "                for j in shoes_Desc_elements:\n",
    "                    shoes_Desc.append(j.text) \n",
    "                shoes_Price_elements=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "                for k in shoes_Price_elements:\n",
    "                    shoes_Price.append(k.text)\n",
    "                #End  \n",
    "                count = len(shoes_Brand)\n",
    "                i = len(shoes_Brand)\n",
    "                next_page_click=driver.find_element_by_xpath(\"//li[@class='pagination-next']\")\n",
    "                next_page_click.click()\n",
    "                time.sleep(3)\n",
    "            if i <=100:\n",
    "                break;\n",
    "            i+=1 \n",
    "    except NoSuchElementException as e:\n",
    "        shoes_Brand.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print (len(shoes_Brand))\n",
    "print (len(shoes_Desc))\n",
    "print (len(shoes_Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Desc</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men KD13 EP Basketball Shoes</td>\n",
       "      <td>Rs. 12995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Textured Sneakers</td>\n",
       "      <td>Rs. 7199Rs. 8999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Eternity Nitro Running</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men REACT MILER 2 Running</td>\n",
       "      <td>Rs. 9770Rs. 11495(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Men Nano X1 Training Shoes</td>\n",
       "      <td>Rs. 7499Rs. 9999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Florsheim</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 6995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Solid Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Open Toe Flats</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                     Product Desc                       Price\n",
       "0        Nike     Men KD13 EP Basketball Shoes                   Rs. 12995\n",
       "1        ALDO            Men Textured Sneakers   Rs. 7199Rs. 8999(20% OFF)\n",
       "2        Nike      Men JORDAN DELTA Basketball                   Rs. 12495\n",
       "3        Puma     Women Eternity Nitro Running                   Rs. 12999\n",
       "4        ALDO                     Men Sneakers                    Rs. 9999\n",
       "..        ...                              ...                         ...\n",
       "95       Nike        Men REACT MILER 2 Running  Rs. 9770Rs. 11495(15% OFF)\n",
       "96     Reebok       Men Nano X1 Training Shoes   Rs. 7499Rs. 9999(25% OFF)\n",
       "97  Florsheim  Men Solid Leather Formal Derbys                    Rs. 6995\n",
       "98       FILA             Women Solid Sneakers                    Rs. 6999\n",
       "99       ALDO             Women Open Toe Flats                    Rs. 8999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we got complete solution of ques.9 ; displaying the data in a dataframe.\n",
    "import pandas as pd\n",
    "shoes_list = pd.DataFrame({})\n",
    "shoes_list[\"Brand\"] = shoes_Brand[:100]\n",
    "shoes_list[\"Product Desc\"] = shoes_Desc[:100]\n",
    "shoes_list[\"Price\"] = shoes_Price[:100]\n",
    "shoes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting out of the opened webpage myntra\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\\\Users\\\\Pooja.Mishra\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the amazon url\n",
    "amazon=\"https://www.amazon.in/\"\n",
    "driver.get(amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Enter “Laptop” in the search field and then click the search icon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_laptop=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "\n",
    "search_laptop.send_keys(\"laptop\")\n",
    "\n",
    "#click the search icon\n",
    "amazon_search=driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "amazon_search.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the data by applying filter of core i7 and core i9 then getting the data by using for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10 10 10\n",
      "10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>₹96,000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...</td>\n",
       "      <td>₹83,990</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Renewed) HP EliteBook 840 G3 Laptop (Core i7 ...</td>\n",
       "      <td>₹44,999</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>₹49,999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP 14 Thin &amp; Light 14\" (35.56cms) FHD Laptop (...</td>\n",
       "      <td>₹84,990</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>₹3,43,099</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>₹79,990</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>₹97,990</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>₹39,999</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo Yoga Slim 7i 11th Gen Intel Core i7 14\"...</td>\n",
       "      <td>₹96,000</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Microsoft Surface Laptop 4 AMD Ryzen™ 7 4980U ...</td>\n",
       "      <td>₹99,990</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Microsoft Surface Laptop 4 AMD Ryzen™ 5 4680U ...</td>\n",
       "      <td>₹1,95,054</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ASUS ROG Zephyrus GX501GI-EI004T 15.6-inch FHD...</td>\n",
       "      <td>₹64,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Acer Nitro 5 Intel Core i5-10th Gen 15.6-inch ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>₹25,999</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>₹35,990</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HP 15 Entry Level 15.6-inch (39.62 cms) HD Lap...</td>\n",
       "      <td>₹27,483</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lenovo IdeaPad S145 10th Gen Intel Core i3 15....</td>\n",
       "      <td>₹24,990</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HP 15 Intel Pentium Gold 6405U Processor Entry...</td>\n",
       "      <td>₹27,499</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ASUS VivoBook 14 (2020) Intel Quad Core Pentiu...</td>\n",
       "      <td>₹18,990</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title      Price Rating\n",
       "0   Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...    ₹96,000     11\n",
       "1   Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...    ₹83,990     11\n",
       "2   (Renewed) HP EliteBook 840 G3 Laptop (Core i7 ...    ₹44,999    736\n",
       "3   Mi Notebook Horizon Edition 14 Intel Core i5-1...    ₹49,999      4\n",
       "4   HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (...    ₹84,990      6\n",
       "5   HP Pavilion Gaming 10th Gen Intel Core i7 Proc...  ₹3,43,099     22\n",
       "6   Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...    ₹79,990    288\n",
       "7   HP Pavilion (2021) Thin & Light 11th Gen Core ...    ₹97,990     61\n",
       "8   Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...    ₹39,999     11\n",
       "9   Lenovo Yoga Slim 7i 11th Gen Intel Core i7 14\"...    ₹96,000     61\n",
       "10  Microsoft Surface Laptop 4 AMD Ryzen™ 7 4980U ...    ₹99,990      9\n",
       "11  Microsoft Surface Laptop 4 AMD Ryzen™ 5 4680U ...  ₹1,95,054    474\n",
       "12  ASUS ROG Zephyrus GX501GI-EI004T 15.6-inch FHD...    ₹64,990       \n",
       "13  Acer Nitro 5 Intel Core i5-10th Gen 15.6-inch ...                  \n",
       "14                                                       ₹25,999    618\n",
       "15                                                       ₹35,990    222\n",
       "16  HP 15 Entry Level 15.6-inch (39.62 cms) HD Lap...    ₹27,483     70\n",
       "17  Lenovo IdeaPad S145 10th Gen Intel Core i3 15....    ₹24,990     21\n",
       "18  HP 15 Intel Pentium Gold 6405U Processor Entry...    ₹27,499    589\n",
       "19  ASUS VivoBook 14 (2020) Intel Quad Core Pentiu...    ₹18,990    171"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "i=0\n",
    "count = 0\n",
    "Laptop_listI9 = pd.DataFrame({})\n",
    "Laptop_listI7 = pd.DataFrame({})\n",
    "try:\n",
    "            Laptop_Title=[]\n",
    "            Laptop_Rating=[]\n",
    "            Laptop_Price=[]\n",
    "            count = len(Laptop_Title)\n",
    "            if count == 0:\n",
    "                corei9_filter=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']\")\n",
    "                for i in corei9_filter:\n",
    "                    if \"Intel Core i9\" in i.text:\n",
    "                        i.click()\n",
    "                        break\n",
    "                time.sleep(5)\n",
    "                #Exctracting the all data from page with xpath attributes\n",
    "                #Begin           \n",
    "                laptop_title_elements=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']/span\")          \n",
    "                for i in laptop_title_elements[:10]:\n",
    "                    Laptop_Title.append(i.text)\n",
    "                laptop_rating_elements=driver.find_elements_by_xpath(\"//span[@class='a-size-base']\")\n",
    "                for j in laptop_rating_elements[:10]:\n",
    "                    if j.text ==\" \":\n",
    "                        Laptop_Rating.append('-') \n",
    "                    else:\n",
    "                        Laptop_Rating.append(j.text)  \n",
    "                laptop_Price_elements=driver.find_elements_by_xpath(\"//a[@class='a-size-base a-link-normal a-text-normal']\")\n",
    "                for k in laptop_Price_elements[:10]:\n",
    "                    Laptop_Price.append(k.text.strip().split('\\n')[0].strip())\n",
    "           \n",
    "               #End   \n",
    "                count = len(Laptop_Title)\n",
    "                print(count)\n",
    "                print (len(Laptop_Title),len(Laptop_Rating),len(Laptop_Price))\n",
    "                time.sleep(3)\n",
    "                if count<=10:\n",
    "                    clear_filter=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item s-navigation-clear-link']/span\")\n",
    "                    for i in clear_filter:\n",
    "                        if \"Clear\" in i.text:\n",
    "                            i.click()\n",
    "                            break\n",
    "            Laptop_listI9[\"Title\"] = pd.Series(Laptop_Title)\n",
    "            Laptop_listI9[\"Price\"] = pd.Series(Laptop_Price)\n",
    "            Laptop_listI9[\"Rating\"] = pd.Series(Laptop_Rating)                \n",
    "            time.sleep(3)\n",
    "            if  count <= 10:\n",
    "                corei7_filter=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']\")\n",
    "                for i in corei7_filter:\n",
    "                    if \"Intel Core i7\" in i.text:\n",
    "                        i.click()\n",
    "                        break\n",
    "                #Exctracting the all data from page with xpath attributes\n",
    "                #Begin\n",
    "                Laptop_Title=[]\n",
    "                Laptop_Rating=[]\n",
    "                Laptop_Price=[]\n",
    "                time.sleep(5)\n",
    "                laptop_titel_elements=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']/span\")          \n",
    "                for i in laptop_titel_elements[:10]:\n",
    "                    Laptop_Title.append(i.text)\n",
    "                laptop_rating_elements=driver.find_elements_by_xpath(\"//span[@class='a-size-base']\")\n",
    "                for j in laptop_rating_elements[:10]:\n",
    "                    if j.text ==\"\":\n",
    "                        Laptop_Rating.append('-') \n",
    "                    else:\n",
    "                        Laptop_Rating.append(j.text) \n",
    "                laptop_Price_elements=driver.find_elements_by_xpath(\"//a[@class='a-size-base a-link-normal a-text-normal']\")\n",
    "                for k in laptop_Price_elements[:10]:\n",
    "                    Laptop_Price.append(k.text.strip().split('\\n')[0].strip())\n",
    "                #End  \n",
    "                Laptop_listI7[\"Title\"] = pd.Series(Laptop_Title)\n",
    "                Laptop_listI7[\"Price\"] = pd.Series(Laptop_Price)\n",
    "                Laptop_listI7[\"Rating\"] = pd.Series(Laptop_Rating)\n",
    "except NoSuchElementException as e:\n",
    "        Laptop_Rating.append('-')\n",
    "print (len(Laptop_Title),len(Laptop_Rating),len(Laptop_Price))\n",
    "#Concating the data of core i7 & core i9\n",
    "df = pd.concat([Laptop_listI7, Laptop_listI9], ignore_index=True)\n",
    "df #storing all data in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
